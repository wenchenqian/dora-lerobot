qwen3 预训练




这个问题 定位了下根因，
本质是，mindspeed-llm 公仓的预训练数据处理脚本 在多进程的情况下 会导致 最终处理的结果不一致，我们自己的数据处理代码没有这个问题

工作流又是 每个节点都会各自进行token化，这就导致了每个节点 token化之后的 bin文件 不一致，loss就起飞了。跟训练参数应该是没有关系的，那几个参数设置了也没生效。

规避办法:  增加 环境变量 WORKS  1 屏蔽多进程。 或者参考我的任务，先处理好，直接加载 处理好的bin和idx文件。



预训练数据为 json 多个数据文件 + 每个worker 都起多进程的情况下可能会引入随机性，导致不同 worker 上最终 tokenize 后的数据顺序不一致。所以之前起任务测的有时候是正常的，有时候又是异常的。
