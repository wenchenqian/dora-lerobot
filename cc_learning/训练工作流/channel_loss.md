loss scale
è¡Œä¸šå¤§æ¨¡å‹å¢é‡é¢„è®­ç»ƒé€šå¸¸ä¼´éšç€å¤§é‡æ•°æ®ä»¥åŠè¾ƒé•¿çš„è®­ç»ƒæ—¶é•¿ï¼Œå¢é‡é¢„è®­ç»ƒå®Œæˆåé€šå¸¸è¿˜éœ€è¦SFTé‡æ–°å¯¹é½ä¸ºå¯å¯¹è¯çš„chatæ¨¡å‹ï¼Œæ­¤æ—¶è¿›è¡Œè¯„æµ‹åå‘ç°æ¨¡å‹æ•ˆæœåŠ£åŒ–ä¸¥é‡å¯èƒ½å·²ç»æµªè´¹äº†è®¸å¤šå®è´µçš„æ—¶é—´ä»¥åŠç®—åŠ›ã€‚megatronåŸç”Ÿçš„lossæ‰“å°æœºåˆ¶ä¸ºæ‰“å°ä¸€ä¸ªbatchæ‰€æœ‰tokençš„å¹³å‡lossï¼Œåœ¨è¡Œä¸šå¢è®­å¸¸è§çš„è¡Œä¸šä¸é€šç”¨æ•°æ®æ¯”ä¾‹1:5çš„åœºæ™¯ä¸‹éš¾ä»¥æœ‰æ•ˆåœ°è§‚å¯Ÿåˆ°è¡Œä¸šæ•°æ®çš„è®­ç»ƒæƒ…å†µï¼Œä¸ºæ­¤æˆ‘ä»¬éœ€è¦channel lossåŠŸèƒ½ï¼Œèƒ½å¤Ÿåˆ†åˆ«æ‰“å°ä¸€ä¸ªbatchå†…ä¸åŒæ•°æ®çš„lossï¼Œä»¥æ­¤è§‚å¯Ÿæ¨¡å‹å¯¹ä¸åŒæ•°æ®çš„å­¦ä¹ æƒ…å†µï¼Œåœ¨è¡Œä¸šæ•°æ®è´¨é‡è¿‡å·®æ—¶èƒ½å¤ŸåŠæ—¶çš„å‘ç°ï¼Œä¸ºæˆ‘ä»¬äº‰å–åˆ°æ›´å¤šçš„æ—¶é—´ã€‚

åŸºäºMegatron Datasetå®ç°channel lossï¼Œæä¾›æ›´å¤šè®­ç»ƒæŒ‡æ ‡

åœ¨æ­¤åŸºç¡€ä¸Šï¼Œå‚è€ƒDynamic Loss-Based Sample Reweighting for Improved Large Language Model Pretrainingè®ºæ–‡ï¼Œå®ç°åŸºäºchannel losså¯¹æŸå¤±è¿›è¡ŒåŠ æƒï¼Œåœ¨é‡‘èï¼Œæ•°å­¦ï¼Œç¼–ç¨‹ç­‰è¯„æµ‹é›†å‡å–å¾—æ•ˆæœæå‡ã€‚

![img.png](img.png)

![image.png](assets/imag4352e.png)

![image.png](assets/imagfdasfe.png)

![image.png](assets/imadsafasdfge.png)

![image.png](assets/imagfdsgge.png)

![image.png](assets/imaggfdsge.png)

![image.png](assets/imafdsafdsge.png)

![image.png](assets/imagfdsafdsae.png)

ä½ æä¾›çš„ `get_batch` å‡½æ•°æ˜¯**å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶**ï¼ˆå¦‚ Megatron-LMï¼‰ä¸­çš„ä¸€ä¸ªå…³é”®æ•°æ®åŠ è½½ç»„ä»¶ã€‚å®ƒè´Ÿè´£åœ¨**å¤æ‚çš„å¹¶è¡Œç­–ç•¥**ï¼ˆTP + PP + CP + DPï¼‰ä¸‹ï¼Œä»å…¨å±€æ•°æ®æµä¸­ä¸ºå½“å‰ GPU **æ­£ç¡®åˆ‡åˆ†å¹¶è¿”å›ä¸€ä¸ªæœ¬åœ° batch**ï¼ŒåŒæ—¶æ”¯æŒå¤šæ•°æ®é›†æ··åˆè®­ç»ƒã€ä½ç½®ç¼–ç é‡ç½®ã€è°ƒè¯•æ‰“å°ç­‰é«˜çº§åŠŸèƒ½ã€‚

### ä¸€ã€æ•´ä½“ç›®æ ‡

> **ä¸ºå½“å‰ GPUï¼ˆrankï¼‰å‡†å¤‡ä¸€ä¸ªç¬¦åˆå…¶å¹¶è¡Œè§’è‰²çš„ mini-batchï¼Œç¡®ä¿ï¼š**
>
> - æ•°æ®åœ¨ TPï¼ˆå¼ é‡å¹¶è¡Œï¼‰ç»´åº¦æ­£ç¡®åˆ‡åˆ†ï¼›
> - åºåˆ—åœ¨ CPï¼ˆä¸Šä¸‹æ–‡å¹¶è¡Œï¼‰ç»´åº¦æ­£ç¡®åˆ‡ç‰‡ï¼›
> - éé¦–/å°¾ PPï¼ˆæµæ°´çº¿å¹¶è¡Œï¼‰é˜¶æ®µä¸åŠ è½½å®Œæ•´æ•°æ®ï¼ˆèŠ‚çœå†…å­˜ï¼‰ï¼›
> - æ”¯æŒå¤šæ•°æ®é›†æ··åˆè®­ç»ƒï¼ˆé€šè¿‡ `dataset_id`ï¼‰ï¼›

---

### äºŒã€èƒŒæ™¯çŸ¥è¯†ï¼šå››ç§å¹¶è¡Œç­–ç•¥

åœ¨ Megatron-LM æˆ–ç±»ä¼¼æ¡†æ¶ä¸­ï¼Œè®­ç»ƒå¤§æ¨¡å‹é€šå¸¸é‡‡ç”¨ç»„åˆå¹¶è¡Œï¼š


| å¹¶è¡Œç±»å‹       | ç¼©å†™ | ä½œç”¨                                 | å¯¹ batch çš„å½±å“                       |
| -------------- | ---- | ------------------------------------ | ------------------------------------- |
| **æ•°æ®å¹¶è¡Œ**   | DP   | ä¸åŒ GPU å¤„ç†ä¸åŒæ ·æœ¬                | æ¯ä¸ª DP rank æ‹¿åˆ°ä¸åŒ batch           |
| **å¼ é‡å¹¶è¡Œ**   | TP   | æ¨¡å‹å±‚å†…æƒé‡åˆ‡åˆ†                     | è¾“å…¥ token embedding éœ€åœ¨ TP ç»´åº¦åˆ‡åˆ† |
| **æµæ°´çº¿å¹¶è¡Œ** | PP   | æ¨¡å‹å±‚é—´åˆ‡åˆ†åˆ°ä¸åŒ GPU               | åªæœ‰é¦–/å°¾ stage éœ€è¦å®Œæ•´ input/output |
| **ä¸Šä¸‹æ–‡å¹¶è¡Œ** | CP   | **åºåˆ—é•¿åº¦åˆ‡åˆ†**ï¼ˆå¦‚ 8K åˆ‡æˆ 4Ã—2Kï¼‰ | åºåˆ—éœ€åœ¨ CP ç»´åº¦åˆ‡ç‰‡                  |

> ğŸ’¡ ä½ çš„ç¯å¢ƒä½¿ç”¨ **NPU**ï¼Œä¸”æ¶‰åŠ `mpu.get_context_parallel_group()`ï¼Œè¯´æ˜å¯ç”¨äº† **CPï¼ˆContext Parallelismï¼‰** â€”â€”è¿™æ˜¯å¤„ç†è¶…é•¿ä¸Šä¸‹æ–‡çš„å…³é”®æŠ€æœ¯ã€‚

---

### ä¸‰ã€ä»£ç é€æ®µè¯¦è§£

#### 1. **æå‰é€€å‡ºï¼šä¸­é—´ PP stage ä¸éœ€è¦å®Œæ•´ batch**

```python
is_middle_stage = not (mpu.is_pipeline_first_stage() or mpu.is_pipeline_last_stage())
pretrain_not_tnd_flags = not args.is_instruction_dataset and not args.reset_position_ids
if pretrain_not_tnd_flags and is_middle_stage:
    return (None,) * 5
```

- **ä¸ºä»€ä¹ˆ**ï¼Ÿ
  - åœ¨ PP ä¸­ï¼Œ**ä¸­é—´ stage åªæ¥æ”¶å‰ä¸€ stage çš„ activationï¼Œä¸ç›´æ¥è¯»åŸå§‹æ•°æ®**ï¼›
  - å®ƒä»¬ä¸éœ€è¦ `input_ids`, `attention_mask` ç­‰åŸå§‹è¾“å…¥ï¼Œåªéœ€åš forward/backwardã€‚
- **æ¡ä»¶é™åˆ¶**ï¼š
  - `not args.is_instruction_dataset`ï¼šå¦‚æœæ˜¯ SFTï¼ˆæŒ‡ä»¤æ•°æ®ï¼‰ï¼Œå¯èƒ½éœ€è¦ metadataï¼ˆå¦‚ `dataset_id`ï¼‰ï¼Œä¸èƒ½ç›´æ¥è·³è¿‡ï¼›
  - `not args.reset_position_ids`ï¼šè‹¥éœ€é‡ç½® position idï¼ˆå¦‚ CP åœºæ™¯ï¼‰ï¼Œå¯èƒ½ä»éœ€éƒ¨åˆ†ä¿¡æ¯ã€‚
- **è¿”å› `(None,) * 5`**ï¼šå‡è®¾ä¸‹æ¸¸ expect 5 ä¸ªè¿”å›å€¼ï¼ˆå¦‚ input_ids, labels, loss_mask, attention_mask, dataset_idï¼‰ã€‚

âœ… **èŠ‚çœå†…å­˜å’Œé€šä¿¡å¼€é”€**ã€‚

---

#### 2. **ä» data_iterator è·å– TP åˆ‡åˆ†åçš„ batch**

```python
batch, actual_seq_len = get_batch_on_this_tp_rank(data_iterator)
```

- **`get_batch_on_this_tp_rank`** æ˜¯å¦ä¸€ä¸ªå‡½æ•°ï¼Œè´Ÿè´£ï¼š
  - ä»å…¨å±€ batch ä¸­ï¼Œ**æŒ‰ TP rank åˆ‡åˆ† embedding ç»´åº¦**ï¼ˆå¦‚ vocab parallelï¼‰ï¼›
  - ä½†**åºåˆ—ç»´åº¦ï¼ˆsequence lengthï¼‰ä»æ˜¯å®Œæ•´çš„**ï¼ˆåç»­ CP ä¼šåˆ‡ï¼‰ï¼›
- **`actual_seq_len`**ï¼šå½“å‰ batch ä¸­**å®é™…æœ€å¤§åºåˆ—é•¿åº¦**ï¼ˆå¯èƒ½ < `args.seq_length`ï¼‰ï¼Œç”¨äº CP å’Œ position id é‡ç½®ã€‚

> ğŸ“Œ æ³¨æ„ï¼šæ­¤æ—¶ `batch` æ˜¯ä¸€ä¸ª dictï¼ŒåŒ…å«ï¼š
>
> ```python
> {
>   'input_ids': [B, L],       # å¯èƒ½å·² TP åˆ‡åˆ†
>   'labels': [B, L],
>   'loss_mask': [B, L],
>   'attention_mask': [B, L],
>   'dataset_id': [B],
>   'document_ids': [B],       # ä»…è°ƒè¯•ç”¨
>   'idx': [B],                # ä»…è°ƒè¯•ç”¨
> }
> ```

---

#### 4. **å¤„ç† position id é‡ç½®ï¼ˆç”¨äº CP æˆ–é•¿ä¸Šä¸‹æ–‡ï¼‰**

```python
if args.reset_position_ids and not args.reset_attention_mask:
    generate_actual_seq_len(batch, actual_seq_len)
```

- **èƒŒæ™¯**ï¼šåœ¨ CP ä¸­ï¼Œåºåˆ—è¢«åˆ‡æˆå¤šæ®µï¼ˆå¦‚ [0:2K], [2K:4K]...ï¼‰ï¼Œæ¯æ®µçš„ position id åº”ä» 0 å¼€å§‹ï¼Œè€Œéå…¨å±€ 0~8Kï¼›
- **`generate_actual_seq_len`**ï¼šå¯èƒ½ç”¨äºç”Ÿæˆ per-segment çš„ position idsï¼›
- **æ¡ä»¶ `not reset_attention_mask`**ï¼šè¯´æ˜ attention mask å·²ç”± CP é€»è¾‘å¤„ç†ï¼Œæ— éœ€é‡ç½®ã€‚

> ğŸ”§ è¿™æ˜¯ **ä¸Šä¸‹æ–‡å¹¶è¡Œ**ï¼ˆCPï¼‰ çš„å…³é”®é…å¥—é€»è¾‘ã€‚

---

#### 5. **æ ¸å¿ƒï¼šCP åˆ‡ç‰‡ â€”â€” æ²¿åºåˆ—ç»´åº¦åˆ‡åˆ† batch**

```python
dataset_id = batch["dataset_id"]
batch["dataset_id"] = None
batch = get_batch_on_this_cp_rank(batch)
batch["dataset_id"] = dataset_id
```

- **ä¸ºä»€ä¹ˆå•ç‹¬å¤„ç† `dataset_id`**ï¼Ÿ

  - `dataset_id` æ˜¯ **per-sample æ ‡é‡**ï¼ˆshape `[B]`ï¼‰ï¼Œ**ä¸éšåºåˆ—é•¿åº¦å˜åŒ–**ï¼›
  - è€Œ `input_ids`, `labels` ç­‰æ˜¯ `[B, L]`ï¼Œéœ€è¦åœ¨ **L ç»´åº¦åˆ‡åˆ†**ï¼›
  - `get_batch_on_this_cp_rank` å‡½æ•°å†…éƒ¨ä¼šå¯¹ `[B, L]` å¼ é‡æŒ‰ CP rank åˆ‡ç‰‡ï¼ˆå¦‚ rank 0 æ‹¿ L//CP ~ 2L//CPï¼‰ï¼›
  - ä½†è‹¥ä¼ å…¥ `dataset_id`ï¼ˆshape `[B]`ï¼‰ï¼Œåˆ‡ç‰‡ä¼šå‡ºé”™ï¼ˆç»´åº¦ä¸åŒ¹é…ï¼‰ã€‚
- **æ‰€ä»¥ä¸´æ—¶ç§»é™¤ `dataset_id` â†’ CP åˆ‡ç‰‡ â†’ å†åŠ å›æ¥**ã€‚

#### 6. **è¿”å›**

```python
return batch.values()
```

- è¿”å› dict çš„ valuesï¼ˆå¦‚ `input_ids, labels, loss_mask, attention_mask, dataset_id`ï¼‰ï¼›
- é¡ºåºéœ€ä¸æ¨¡å‹ forward çš„å‚æ•°é¡ºåºä¸€è‡´ã€‚

---

### å››ã€å…³é”®æœºåˆ¶æ€»ç»“


| æœºåˆ¶                                | ä½œç”¨                            |
| ----------------------------------- | ------------------------------- |
| **PP ä¸­é—´ stage è·³è¿‡æ•°æ®åŠ è½½**      | èŠ‚çœå†…å­˜ï¼Œç¬¦åˆ PP æ•°æ®æµ        |
| **TP åˆ‡åˆ†åœ¨ data loading é˜¶æ®µå®Œæˆ** | é¿å…åç»­é€šä¿¡                    |
| **CP åˆ‡ç‰‡åœ¨åºåˆ—ç»´åº¦è¿›è¡Œ**           | æ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡è®­ç»ƒ              |
| **dataset_id ä¸å‚ä¸ CP åˆ‡ç‰‡**       | ä¿æŠ¤ per-sample metadata å®Œæ•´æ€§ |
| **è°ƒè¯•ä¿¡æ¯ä»… rank 0 æ‰“å°**          | é¿å…æ—¥å¿—å†—ä½™                    |

âœ… `get_batch` æ­£æ˜¯è¿™ä¸€åˆ‡çš„**æ•°æ®å…¥å£**ï¼š

- å®ƒç¡®ä¿ **æ¯ä¸ª GPU æ‹¿åˆ°æ­£ç¡®çš„æ•°æ®åˆ‡ç‰‡**ï¼›
- ä¿ç•™ `dataset_id` ä¾›åç»­ `get_channel_loss_return_dict` ç»Ÿè®¡ per-dataset lossï¼›
- é€šè¿‡ `actual_seq_len` å’Œ position id é‡ç½®ï¼Œ**æ”¯æŒ CP ä¸‹çš„æ­£ç¡®è®­ç»ƒ**ã€‚

---

### æ€»ç»“

`get_batch` æ˜¯ä¸€ä¸ª**é«˜åº¦é€‚é… Megatron-LM åˆ†å¸ƒå¼è®­ç»ƒèŒƒå¼çš„æ•°æ®åŠ è½½å‡½æ•°**ï¼Œå®ƒåœ¨**TP/PP/CP/DP å››é‡å¹¶è¡Œ**ä¸‹ï¼Œç²¾ç¡®åœ°ä¸ºæ¯ä¸ª GPU æä¾›æ‰€éœ€çš„æ•°æ®åˆ‡ç‰‡ï¼ŒåŒæ—¶ä¿ç•™å¤šæ•°æ®é›†è®­ç»ƒæ‰€éœ€çš„ metadataï¼ˆå¦‚ `dataset_id`ï¼‰ï¼Œå¹¶æ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡å’Œè°ƒè¯•éœ€æ±‚ã€‚
**å®ƒæ˜¯ä½ å®ç°â€œé¢†åŸŸå¢é‡é¢„è®­ç»ƒ + chat èƒ½åŠ›ä¿ç•™â€è¿™ä¸€å¤æ‚è®­ç»ƒç›®æ ‡çš„åº•å±‚æ•°æ®ä¿éšœ**ã€‚

## æ•°æ®é…æ¯”

### æ•°æ®é›†

1ï¼‰æŒ‰ç…§tokenæ•°é‡

è®¾ç½®åˆå§‹æ¯”ä¾‹  20M

è®¾ç½® Budgetï¼š é‡‘èï¼šæ•°å­¦ï¼šç¼–ç¨‹ï¼šé€»è¾‘+å¯¹è¯= 3:2:2:3

1ï¼Œ 5M

2ï¼‰æŒ‰ç…§æ¡æ•° 5.2W æ¡

é‡‘è1W:

æ…¢æ€è€ƒ:   ä¿¡è´·2ä¸ª(482) + é‡‘èå¯¹é½(572) +é—®ç­”(182) +Openfindata(2363) + æ–‡æœ¬ç”Ÿæˆ (113) æ€»å…± 3712 /   å¿«æ€è€ƒï¼šfast\_finance\_40k\_debug.json å’Œ fast\_icbc\_0327.json ä¸­é‡‡æ · 16300 æ¡æ ·æœ¬ã€‚

æ•°å­¦1W:  æ…¢ 7.5Kï¼Œå¿«2.5K

ç¼–ç¨‹1W: æ…¢ 7.5Kï¼Œå¿«2.5K

é€»è¾‘1Wï¼š æ…¢ 7.5Kï¼Œå¿«2.5K

é€šç”¨1W: å¯¹é½: æ…¢ 7.5Kï¼Œå¿«2.5Kï¼Œ +å¯¹é½(2113)

reasoning : non-reasoning data ï¼Ÿ å‚è€ƒR1çš„æŠ€æœ¯æŠ¥å‘Š 3:1


![img_10.png](img_10.png)




![img_11.png](img_11.png)

![img_12.png](img_12.png)


åŠ¨æœºï¼š**ä¸ºä»€ä¹ˆè¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€çš„reweightï¼Ÿ**

as the model learns it could be beneficial to reduce its weight

æœ‰äº›æ ·æœ¬è®­ç»ƒåˆæœŸå¾ˆéš¾å­¦ï¼Œèµ‹äºˆå¤§æƒé‡ï¼Œéšç€è®­ç»ƒè¿›åº¦å­¦åˆ°äº†ï¼Œæƒé‡å¯ä»¥é™ä½ã€‚

æ ·æœ¬é‡å¾ˆå¤šï¼Œæ— æ³•è®°å½•æ¯ä¸ªæ ·æœ¬çš„æŸå¤±

![image.png](assets/imafdsafdge.png)

![image.png](assets/imafdsafdasge.png)
