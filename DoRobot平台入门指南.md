# DoRobot平台入门指南

> GOSIM 2025 - Dora LeRobot Hackathon 版本

## 目录
1. [平台概述](#平台概述)
2. [核心架构](#核心架构)
3. [底层技术原理](#底层技术原理)
4. [SO101机器人使用指南](#so101机器人使用指南)
5. [数据采集流程](#数据采集流程)
6. [模型训练流程](#模型训练流程)
7. [模型推理流程](#模型推理流程)
8. [常见问题与解决方案](#常见问题与解决方案)

---

## 平台概述

### 什么是DoRobot平台？

DoRobot是一个基于**Dora**和**LeRobot**技术栈构建的机器人学习平台，专门用于机器人数据采集、模型训练和智能控制。它让机器人能够通过观察人类操作来学习复杂的任务。

### 核心特点

- **🤖 多机器人支持**: 支持SO101、ALOHA、Pika等多种机器人
- **📊 智能数据管理**: 基于LeRobot的数据集格式，支持视频、音频、传感器数据
- **🧠 多种AI模型**: 集成ACT、Diffusion、TDMPC等先进的学习算法
- **🔄 实时数据流**: 基于Dora的高性能数据流处理
- **📹 可视化支持**: 集成Rerun进行实时3D可视化

### 适用场景

- 机器人技能学习（抓取、放置、操作等）
- 机器人行为模仿
- 机器人任务自动化
- 机器人技能评估

---

## 核心架构

### 整体架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                        DoRobot平台架构                           │
├─────────────────────────────────────────────────────────────────┤
│  用户界面层                                                      │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │   数据采集   │  │   模型训练   │  │   模型推理   │              │
│  │   界面      │  │   界面      │  │   界面      │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
├─────────────────────────────────────────────────────────────────┤
│  核心服务层                                                      │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │   Daemon    │  │   Record    │  │  Inference  │              │
│  │  (守护进程)  │  │  (记录器)   │  │  (推理器)   │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
├─────────────────────────────────────────────────────────────────┤
│  数据处理层                                                      │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  DoRobot    │  │   LeRobot   │  │    Dora     │              │
│  │  Dataset    │  │  Policies   │  │  DataFlow   │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
├─────────────────────────────────────────────────────────────────┤
│  硬件抽象层                                                      │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │   机器人     │  │   摄像头     │  │   传感器     │              │
│  │   Manipulator│  │   Camera    │  │   Sensors   │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
```

### 核心组件说明

#### 1. Daemon (守护进程)
- **作用**: 系统的核心协调器，负责管理机器人连接、数据同步和任务调度
- **功能**: 
  - 机器人设备连接管理
  - 实时数据采集和同步
  - 任务状态监控
  - 错误处理和恢复

#### 2. Record (记录器)
- **作用**: 负责将机器人的操作数据记录成训练数据集
- **功能**:
  - 多模态数据采集（图像、关节角度、音频等）
  - 数据格式化和存储
  - 数据质量检查
  - 数据集版本管理

#### 3. Inference (推理器)
- **作用**: 使用训练好的模型控制机器人执行任务
- **功能**:
  - 模型加载和推理
  - 实时动作生成
  - 安全监控
  - 任务执行控制

---

## 底层技术原理

### Dora技术栈

**Dora**是一个高性能的实时数据流处理框架，在DoRobot平台中扮演"神经系统"的角色：

#### 核心概念
- **DataFlow**: 数据流图，定义了数据如何在各个组件间流动
- **Node**: 处理节点，每个节点负责特定的数据处理任务
- **Event**: 事件驱动，支持异步、非阻塞的数据处理

#### 在DoRobot中的作用
```
机器人传感器 → Dora节点 → 数据处理 → 决策模块 → 机器人执行器
     ↓              ↓           ↓          ↓           ↓
   图像数据      图像处理    特征提取   动作规划    关节控制
   关节数据      数据同步    状态估计   安全检查    执行反馈
```

### LeRobot技术栈

**LeRobot**是Hugging Face开发的机器人学习框架，提供标准化的数据集格式和模型训练工具：

#### 核心特性
- **标准化数据集格式**: 统一的多模态数据存储格式
- **预训练模型库**: 提供多种先进的机器人学习算法
- **模型训练工具**: 完整的训练、验证、测试流程
- **模型部署支持**: 支持多种部署方式

#### 支持的学习算法
1. **ACT (Action Chunking Transformer)**: 基于Transformer的动作预测
2. **Diffusion Policy**: 基于扩散模型的策略学习
3. **TDMPC**: 基于模型预测控制的强化学习
4. **PI0**: 基于模仿学习的策略优化

### 数据流架构

#### 数据采集流程
```
人类操作 → 机器人传感器 → 数据预处理 → 格式转换 → 数据集存储
    ↓           ↓            ↓          ↓          ↓
  示教动作    多模态数据    数据清洗    LeRobot格式  本地/Hub存储
```

#### 训练流程
```
数据集 → 数据加载器 → 模型训练 → 模型验证 → 模型保存
   ↓         ↓          ↓         ↓         ↓
 LeRobot   批处理     损失计算   性能评估   检查点保存
 格式      数据增强   反向传播   指标监控   模型导出
```

#### 推理流程
```
传感器数据 → 数据预处理 → 模型推理 → 动作后处理 → 机器人执行
     ↓           ↓          ↓          ↓           ↓
   实时观测    格式转换    动作预测   安全检查    关节控制
```

---

## SO101机器人使用指南

### 硬件配置

SO101是一个双臂协作机器人系统，包含：
- **主臂 (Leader Arm)**: 用于示教，人类直接操作
- **从臂 (Follower Arm)**: 用于执行，机器人自动控制
- **摄像头系统**: 提供视觉反馈
- **通信接口**: USB/串口连接

### 环境搭建

#### 1. 系统要求
- Ubuntu 20.04+ 或兼容Linux系统
- Python 3.11
- CUDA支持（推荐，用于模型训练）
- 至少8GB RAM

#### 2. 安装步骤

**步骤1: 克隆项目**
```bash
git clone https://github.com/DoRobot-Project/DoRobot-Preview.git
cd DoRobot-Preview
```

**步骤2: 创建Python环境**
```bash
# 创建DoRobot主环境
conda create --name op python==3.11
conda activate op

# 安装主项目
pip install -e .

# 安装PyTorch (根据你的GPU选择)
pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118

# 安装音频支持
sudo apt install libportaudio2
```

**步骤3: 创建SO101专用环境**
```bash
# 新终端窗口
conda create --name dr-robot-so101 python==3.10
conda activate dr-robot-so101

# 安装SO101机器人驱动
cd operating_platform/robot/robots/so101_v1
pip install -e .
```

#### 3. 硬件连接

**摄像头连接**:
```bash
# 检查摄像头设备
ls /dev/video*

# 应该看到类似输出:
# /dev/video0 /dev/video1 /dev/video2 /dev/video3
```

**机器人连接**:
```bash
# 检查机器人USB连接
ls /dev/ttyACM*

# 应该看到:
# /dev/ttyACM0  # 主臂
# /dev/ttyACM1  # 从臂
```

### 校准流程

在开始使用前，需要对机器人进行校准：

**校准主臂**:
```bash
cd operating_platform/robot/components/arm_normal_so101_v1/
dora run dora_calibrate_leader.yml
```

**校准从臂**:
```bash
dora run dora_calibrate_follower.yml
```

---

## 数据采集流程

### 准备工作

1. **确保硬件连接正常**
2. **启动Dora数据流**
3. **准备数据采集脚本**

### 详细步骤

#### 步骤1: 启动数据流
```bash
cd operating_platform/robot/robots/so101_v1
conda activate dr-robot-so101
dora run dora_teleoperate_dataflow.yml
```

#### 步骤2: 启动数据采集
```bash
# 新终端窗口
conda activate op
bash scripts/run_so101_cli.sh
```

#### 步骤3: 配置采集参数
编辑 `scripts/run_so101_cli.sh` 文件：
```bash
python operating_platform/core/main.py \
    --robot.type=so101 \
    --record.repo_id="your-task-name" \
    --record.single_task="描述你的任务，例如：抓取红色积木并放入盒子"
```

#### 步骤4: 执行数据采集
1. **启动采集**: 运行脚本后，系统会开始倒计时
2. **示教操作**: 倒计时结束后，手动操作主臂完成目标任务
3. **结束episode**: 按 'n' 键结束当前episode，开始新的episode
4. **完成采集**: 按 'e' 键完成所有数据采集

### 数据采集最佳实践

#### 1. 任务设计
- **明确目标**: 每个任务应该有清晰的目标和成功标准
- **适度复杂度**: 避免过于复杂的任务，建议从简单任务开始
- **一致性**: 保持操作方式的一致性，便于模型学习

#### 2. 数据质量
- **充足数据**: 建议每个任务采集50-100个episode
- **多样性**: 包含不同的初始状态和操作路径
- **质量检查**: 定期检查采集的数据质量

#### 3. 操作技巧
- **平滑操作**: 避免突然的急停或急转
- **合理速度**: 保持适中的操作速度
- **完整动作**: 确保每个动作都有明确的开始和结束

### 数据存储结构

采集的数据会按以下结构存储：
```
/data/dorobot/
└── 20241201/           # 日期目录
    └── user/           # 用户目录
        └── your-task-name/  # 任务目录
            ├── data/        # 数据文件
            │   ├── chunk-000/
            │   │   ├── episode_000000.parquet
            │   │   └── ...
            │   └── ...
            ├── meta/        # 元数据
            │   ├── info.json
            │   ├── stats.json
            │   └── tasks.jsonl
            └── videos/      # 视频文件
                └── chunk-000/
                    ├── observation.images.image_top/
                    └── observation.images.image_wrist/
```

---

## 模型训练流程

### 训练环境准备

#### 1. 服务器配置
- **GPU**: 推荐RTX 4090或A100
- **内存**: 至少32GB RAM
- **存储**: 至少500GB SSD空间

#### 2. 训练脚本配置
```bash
# 训练脚本示例
python operating_platform/core/train.py \
    --dataset.repo_id="your-task-name" \
    --dataset.root="/data/dorobot/20241201/user/your-task-name" \
    --policy.type="act" \
    --policy.device="cuda" \
    --train.batch_size=8 \
    --train.steps=10000 \
    --output_dir="./checkpoints/your-task-name"
```

### 训练参数说明

#### 数据集参数
- `dataset.repo_id`: 数据集名称
- `dataset.root`: 数据集本地路径
- `dataset.episodes`: 指定使用的episode（可选）

#### 模型参数
- `policy.type`: 模型类型（act, diffusion, tdmpc等）
- `policy.device`: 训练设备（cuda, cpu）
- `policy.use_amp`: 是否使用混合精度训练

#### 训练参数
- `train.batch_size`: 批次大小
- `train.steps`: 训练步数
- `train.learning_rate`: 学习率
- `train.save_freq`: 保存频率

### 训练监控

#### 1. 日志监控
训练过程中会输出详细的日志信息：
```
Step: 1000 | Loss: 0.123 | LR: 1e-4 | Time: 2.5s
Step: 2000 | Loss: 0.098 | LR: 9e-5 | Time: 2.3s
...
```

#### 2. 模型检查点
训练过程中会定期保存检查点：
```
checkpoints/your-task-name/
├── step_1000/
│   ├── policy.safetensors
│   ├── optimizer.pt
│   └── config.json
├── step_2000/
└── ...
```

#### 3. 性能评估
训练过程中会进行模型评估：
- **成功率**: 任务完成的成功率
- **平均奖励**: 任务执行的平均奖励
- **执行时间**: 任务执行的平均时间

### 训练优化技巧

#### 1. 数据预处理
- **数据增强**: 使用图像增强提高数据多样性
- **数据平衡**: 确保不同类别的数据平衡
- **数据清洗**: 移除低质量的数据

#### 2. 超参数调优
- **学习率**: 从1e-4开始，根据收敛情况调整
- **批次大小**: 根据GPU内存调整，通常8-32
- **训练步数**: 根据数据集大小调整，通常10000-50000步

#### 3. 模型选择
- **ACT**: 适合大多数操作任务，训练稳定
- **Diffusion**: 适合复杂操作，但训练时间较长
- **TDMPC**: 适合需要精确控制的任务

---

## 模型推理流程

### 推理环境准备

#### 1. 模型部署
```bash
# 加载训练好的模型
python operating_platform/core/inference.py \
    --dataset.repo_id="your-task-name" \
    --dataset.root="/data/dorobot/20241201/user/your-task-name" \
    --policy.path="./checkpoints/your-task-name/step_10000" \
    --robot.type="so101" \
    --inference.single_task="抓取红色积木并放入盒子"
```

#### 2. 安全准备
- **紧急停止**: 确保紧急停止按钮可用
- **工作空间**: 清理工作空间，移除障碍物
- **监控**: 保持对机器人状态的监控

### 推理执行流程

#### 步骤1: 模型加载
系统会自动加载训练好的模型和配置：
```
Loading model from: ./checkpoints/your-task-name/step_10000
Model type: ACT
Device: cuda
Task: 抓取红色积木并放入盒子
```

#### 步骤2: 环境初始化
- 机器人连接检查
- 传感器数据验证
- 初始位置设置

#### 步骤3: 任务执行
1. **观测**: 系统实时获取环境状态
2. **推理**: 模型根据观测生成动作
3. **执行**: 机器人执行生成的动作
4. **反馈**: 系统监控执行结果

#### 步骤4: 任务完成
- 任务成功完成或达到最大步数
- 系统记录执行结果
- 机器人回到安全位置

### 推理监控

#### 1. 实时监控
- **摄像头画面**: 实时显示机器人操作
- **关节状态**: 显示各关节的角度和速度
- **动作预测**: 显示模型预测的下一步动作

#### 2. 性能指标
- **成功率**: 任务完成的成功率
- **执行时间**: 任务执行的时间
- **动作平滑度**: 动作的平滑程度

#### 3. 安全监控
- **关节限制**: 监控关节是否超出安全范围
- **碰撞检测**: 检测是否发生碰撞
- **异常处理**: 处理异常情况

### 推理优化

#### 1. 模型优化
- **量化**: 使用模型量化减少推理时间
- **剪枝**: 移除不重要的网络连接
- **蒸馏**: 使用知识蒸馏压缩模型

#### 2. 推理加速
- **批处理**: 批量处理多个观测
- **缓存**: 缓存常用的计算结果
- **并行**: 使用多线程并行处理

#### 3. 鲁棒性提升
- **集成**: 使用多个模型集成提高鲁棒性
- **不确定性**: 估计预测的不确定性
- **自适应**: 根据环境变化自适应调整

---

## 常见问题与解决方案

### 硬件连接问题

#### 问题1: 摄像头无法识别
**症状**: `ls /dev/video*` 显示设备数量不正确
**解决方案**:
```bash
# 检查USB连接
lsusb

# 重新插拔摄像头
sudo modprobe -r uvcvideo
sudo modprobe uvcvideo

# 检查权限
sudo chmod 666 /dev/video*
```

#### 问题2: 机器人无法连接
**症状**: 机器人无响应或连接超时
**解决方案**:
```bash
# 检查串口权限
sudo chmod 666 /dev/ttyACM*

# 检查串口配置
sudo stty -F /dev/ttyACM0 115200

# 重启机器人电源
```

### 软件环境问题

#### 问题1: 依赖包冲突
**症状**: 导入模块时出现版本冲突错误
**解决方案**:
```bash
# 重新创建环境
conda env remove -n op
conda create --name op python==3.11

# 使用pip安装
pip install --no-deps -e .
```

#### 问题2: CUDA版本不匹配
**症状**: PyTorch无法使用GPU
**解决方案**:
```bash
# 检查CUDA版本
nvidia-smi

# 重新安装匹配的PyTorch版本
pip uninstall torch torchvision torchaudio
pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118
```

### 数据采集问题

#### 问题1: 数据同步问题
**症状**: 图像和关节数据不同步
**解决方案**:
- 检查系统时间同步
- 调整数据采集频率
- 使用时间戳对齐

#### 问题2: 存储空间不足
**症状**: 数据采集过程中出现存储错误
**解决方案**:
```bash
# 检查磁盘空间
df -h

# 清理临时文件
rm -rf /tmp/*

# 移动数据到其他位置
mv /data/dorobot /path/to/larger/disk/
```

### 训练问题

#### 问题1: 训练不收敛
**症状**: 损失函数不下降或震荡
**解决方案**:
- 降低学习率
- 增加训练数据
- 调整模型架构
- 检查数据质量

#### 问题2: 内存不足
**症状**: 训练过程中出现OOM错误
**解决方案**:
- 减少批次大小
- 使用梯度累积
- 启用混合精度训练
- 使用数据并行

### 推理问题

#### 问题1: 推理速度慢
**症状**: 模型推理延迟过高
**解决方案**:
- 使用模型量化
- 优化输入数据格式
- 使用更快的推理后端
- 减少模型复杂度

#### 问题2: 动作不准确
**症状**: 机器人执行的动作与预期不符
**解决方案**:
- 检查模型训练质量
- 调整动作后处理
- 增加安全约束
- 使用更精确的传感器

---

## 总结

DoRobot平台是一个功能强大的机器人学习平台，通过结合Dora的高性能数据流处理和LeRobot的先进学习算法，为机器人技能学习提供了完整的解决方案。

### 关键优势
1. **易用性**: 提供简单易用的接口和脚本
2. **可扩展性**: 支持多种机器人和学习算法
3. **高性能**: 基于Dora的实时数据处理
4. **标准化**: 基于LeRobot的数据格式和模型

### 学习建议
1. **从简单开始**: 先掌握基本的数据采集和训练流程
2. **逐步深入**: 理解底层原理，掌握高级功能
3. **实践为主**: 通过实际项目加深理解
4. **社区支持**: 积极参与社区讨论，获取帮助

### 下一步
- 尝试不同的学习算法
- 探索更复杂的机器人任务
- 参与开源社区贡献
- 开发自定义的机器人应用

---

*本指南基于DoRobot-Preview版本编写，如有问题请参考项目文档或联系开发团队。*
